## 1. 기술 스택

### LLM
- **주요 모델**: OpenAI GPT-4o
  - 용도: 모든 에이전트의 핵심 추론 및 생성 엔진
  - 매개변수:
    - 기본 temperature: 각 에이전트 역할별 최적화 (감독 에이전트: 0.2, 창의적 에이전트: 0.7)
    - max_tokens: 작업별 최적화 (4,096~8,192)
    - 시스템 메시지: 에이전트별 페르소나 및 지시사항 포함
  - 호출 최적화:
    - 배치 처리를 통한 API 호출 최소화
    - 컨텍스트 크기 최적화를 위한 청킹 전략 적용

### 벡터 DB
- **주요 시스템**: Chroma
  - 대안: FAISS(로컬 처리용), Pinecone(클라우드 기반 확장용)
- **임베딩 모델**: OpenAI text-embedding-3-large
  - 차원: 3,072
  - 정규화: L2 정규화 적용
- **인덱스 설정**:
  - HNSW 파라미터: M=64, efConstruction=256

### 검색 시스템
- **웹 검색 API**:
  - Google Custom Search API
    - GOOGLE_API_KEY, GOOGLE_CSE_ID_GENERA (일반 검색용)
    - GOOGLE_CSE_ID_SCHOLAR (학술 검색용)
  - arXiv API (학술 논문 전문 검색)
- **검색 통합 레이어**:
  - 다중 소스 쿼리 및 결과 통합 시스템
  - 중복 제거 및 관련성 재순위화 알고리즘

### 프레임워크
- **코어 프레임워크**: LangGraph
  - 에이전트 라우팅 및 워크플로 관리
  - 상태 관리 및 컨텍스트 처리
- **보조 프레임워크**:
  - LangChain: 컴포넌트 통합 및 체인 구성
  - FastAPI: RESTful API 제공
  - Pydantic: 데이터 검증 및 설정 관리

### 데이터 처리
- **파이썬 라이브러리**:
  - pandas, numpy: 데이터 처리 및 분석
  - matplotlib, plotly: 데이터 시각화
  - scikit-learn: 기본 통계 및 ML 기능
  - beautifulsoup4, playwright: 웹 크롤링 및 파싱

## 2. 코드 아키텍처

### 핵심 모듈

#### 시스템 코어
```
core/
├── config.py             # 시스템 구성 및 환경 설정
├── logging_manager.py    # 로깅 시스템
├── state_manager.py      # 글로벌 상태 관리
├── event_bus.py          # 이벤트 기반 통신 시스템
└── error_handler.py      # 예외 처리 및 복구 메커니즘
```

#### 에이전트 모듈
```
agents/
├── base.py               # 기본 에이전트 클래스
├── supervisor.py         # 감독 에이전트
├── rag_agent.py          # RAG 에이전트
├── web_search_agent.py   # 웹 검색 에이전트
├── data_analysis_agent.py # 데이터 분석 에이전트
├── psychological_agent.py # 심리분석 에이전트
├── report_writer_agent.py # 보고서 작성 에이전트
└── prompts/              # 에이전트별 프롬프트 템플릿
    ├── supervisor/
    ├── rag/
    └── ...
```

#### 검색 및 지식 모듈
```
knowledge/
├── vectordb/
│   ├── chroma_client.py  # Chroma DB 클라이언트
│   ├── embedding.py      # 임베딩 생성 및 관리
│   └── index_manager.py  # 인덱스 관리
├── search/
│   ├── google_search.py  # Google 검색 API 래퍼
│   ├── arxiv_search.py   # arXiv API 래퍼
│   └── search_router.py  # 검색 라우팅 및 통합
└── document_processor/
    ├── chunker.py        # 문서 청킹 시스템
    ├── parser.py         # 다양한 형식 파서(PDF, HTML 등)
    └── metadata_extractor.py # 메타데이터 추출기
```

#### 데이터 처리 모듈
```
data_processing/
├── analysis/
│   ├── statistics.py     # 통계 분석 도구
│   ├── timeseries.py     # 시계열 분석
│   └── correlation.py    # 상관관계 분석
├── visualization/
│   ├── chart_generator.py # 차트 생성기
│   └── plot_templates.py  # 시각화 템플릿
└── formatters/
    ├── report_formatter.py # 보고서 포맷팅
    └── data_exporter.py    # 데이터 내보내기
```

#### 워크플로 및 API 모듈
```
workflow/
├── graph_definitions.py  # LangGraph 워크플로 정의
├── router.py             # 쿼리-작업 라우팅 시스템
└── executor.py           # 작업 실행 관리자

api/
├── endpoints.py          # API 엔드포인트
├── schemas.py            # 요청/응답 스키마
└── middleware.py         # API 미들웨어
```

### 클래스 다이어그램

#### 기본 에이전트 구조
```
BaseAgent
├── Properties
│   ├── agent_id: str
│   ├── role: str
│   ├── llm_config: Dict
│   └── state: Dict
├── Methods
│   ├── initialize()
│   ├── process_message(message: Dict) -> Dict
│   ├── generate_response(context: Dict) -> str
│   └── update_state(new_state: Dict)

SupervisorAgent (extends BaseAgent)
├── Properties
│   ├── managed_agents: List[BaseAgent]
│   └── task_registry: Dict
├── Methods
│   ├── analyze_query(query: str) -> Dict
│   ├── create_task_plan(query: str) -> List[Task]
│   ├── assign_task(task: Task, agent: BaseAgent)
│   ├── monitor_progress() -> Dict
│   └── validate_result(result: Dict) -> bool

SpecializedAgent (extends BaseAgent) [Abstract]
├── Properties
│   ├── specialized_tools: List[Tool]
│   └── capability_registry: Dict
├── Methods
│   ├── execute_task(task: Task) -> Dict
│   ├── request_information(query: Dict) -> Dict
│   └── report_progress(status: str, progress: float)
```

#### 검색 시스템 구조
```
SearchProvider [Interface]
├── Methods
│   ├── search(query: str, params: Dict) -> List[SearchResult]
│   └── get_document(doc_id: str) -> Document

GoogleSearchProvider (implements SearchProvider)
├── Properties
│   ├── api_key: str
│   ├── cse_id: str
│   └── request_config: Dict
├── Methods
│   ├── search(query: str, params: Dict) -> List[SearchResult]
│   ├── get_document(doc_id: str) -> Document
│   └── format_results(raw_results: Dict) -> List[SearchResult]

ArxivSearchProvider (implements SearchProvider)
...

SearchRouter
├── Properties
│   ├── providers: Dict[str, SearchProvider]
│   └── routing_rules: Dict
├── Methods
│   ├── route_query(query: str) -> Dict[str, List[SearchResult]]
│   ├── combine_results(results: Dict) -> List[SearchResult]
│   └── deduplicate_results(results: List[SearchResult]) -> List[SearchResult]
```

## 3. 통합 요구사항

### API 사양

#### OpenAI API 통합
```python
# OpenAI API 구성
openai_config = {
    "model": "gpt-4o",
    "api_key": os.environ.get("OPENAI_API_KEY"),
    "default_params": {
        "temperature": 0.2,
        "max_tokens": 4096,
        "top_p": 1.0
    },
    "retry_config": {
        "max_retries": 3,
        "backoff_factor": 2,
        "status_forcelist": [429, 500, 502, 503, 504]
    }
}
```

#### Google Search API 통합
```python
# Google Search API 구성
google_search_config = {
    "api_key": os.environ.get("GOOGLE_API_KEY"),
    "general_cse_id": os.environ.get("GOOGLE_CSE_ID_GENERA"),
    "scholar_cse_id": os.environ.get("GOOGLE_CSE_ID_SCHOLAR"),
    "params": {
        "num": 10,            # 결과 수
        "safe": "active",     # 안전 검색
        "dateRestrict": None  # 날짜 제한(필요시 설정)
    }
}
```

#### arXiv API 통합
```python
# arXiv API 구성
arxiv_config = {
    "search_params": {
        "max_results": 10,
        "sort_by": "relevance",
        "sort_order": "descending"
    },
    "retry_config": {
        "max_retries": 3,
        "backoff_factor": 1.5
    }
}
```

### 데이터 형식

#### 에이전트 간 메시지 스키마
```python
# Pydantic 모델 정의
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Any, Literal
from datetime import datetime

class MessageContent(BaseModel):
    action: str
    parameters: Dict[str, Any] = {}
    data: Dict[str, Any] = {}
    metadata: Dict[str, Any] = {}

class AgentMessage(BaseModel):
    message_id: str = Field(..., description="고유 메시지 식별자")
    timestamp: datetime = Field(default_factory=datetime.now)
    sender: str = Field(..., description="발신 에이전트 ID")
    receiver: str = Field(..., description="수신 에이전트 ID 또는 'broadcast'")
    message_type: Literal["request", "response", "notification", "error"]
    priority: Literal["high", "normal", "low"] = "normal"
    content: MessageContent
    references: List[str] = []
    status: Literal["pending", "processing", "completed", "failed"] = "pending"
```

#### 검색 결과 스키마
```python
class SearchResult(BaseModel):
    result_id: str
    source: Literal["google", "google_scholar", "arxiv"]
    title: str
    snippet: str
    url: str
    published_date: Optional[datetime] = None
    authors: List[str] = []
    citation_count: Optional[int] = None
    relevance_score: float
    metadata: Dict[str, Any] = {}
```

#### 작업 스키마
```python
class Task(BaseModel):
    task_id: str
    query_id: str
    task_type: str
    description: str
    assigned_agent: str
    dependencies: List[str] = []
    parameters: Dict[str, Any] = {}
    priority: int = 1
    deadline: Optional[datetime] = None
    status: Literal["pending", "in_progress", "completed", "failed"] = "pending"
    progress: float = 0.0
    result: Optional[Dict[str, Any]] = None
```

### 오류 처리

#### 예외 계층
```
SystemException
├── NetworkException
│   ├── APIConnectionError
│   ├── TimeoutError
│   └── RateLimitError
├── DataException
│   ├── ValidationError
│   ├── DataFormatError
│   └── StorageError
├── AgentException
│   ├── PromptExecutionError
│   ├── ContextLimitError
│   └── AgentCommunicationError
└── ResourceException
    ├── AuthenticationError
    ├── QuotaExceededError
    └── ConfigurationError
```

#### 오류 처리 전략
```python
# 오류 처리자 구성
error_handler_config = {
    "retryable_errors": [
        "APIConnectionError", 
        "TimeoutError", 
        "RateLimitError"
    ],
    "retry_strategies": {
        "exponential_backoff": {
            "initial_delay_ms": 1000,
            "max_delay_ms": 60000,
            "multiplier": 2.0
        },
        "circuit_breaker": {
            "failure_threshold": 5,
            "recovery_timeout_ms": 30000
        }
    },
    "fallback_strategies": {
        "alternative_api": True,
        "cached_responses": True,
        "degraded_operation": True
    },
    "logging": {
        "log_level": "ERROR",
        "include_stack_trace": True,
        "notify_threshold": "ERROR"
    }
}
```

## 4. 개발 환경

### 의존성

#### 핵심 패키지
```
# requirements.txt
langchain==0.1.9
langgraph==0.0.24
langchain-openai==0.0.5
openai==1.12.0
chromadb==0.4.22
faiss-cpu==1.7.4
google-api-python-client==2.108.0
arxiv==2.0.0
pydantic==2.5.3
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-dotenv==1.0.0
pandas==2.1.3
numpy==1.26.2
matplotlib==3.8.2
plotly==5.18.0
scipy==1.11.4
scikit-learn==1.3.2
beautifulsoup4==4.12.2
playwright==1.40.0
asyncio==3.4.3
aiohttp==3.9.1
```

### 환경 변수
```
# .env
# API 키
OPENAI_API_KEY=sk-...
GOOGLE_API_KEY=...
GOOGLE_CSE_ID_GENERA=...
GOOGLE_CSE_ID_SCHOLAR=...

# 시스템 구성
LOG_LEVEL=INFO
ENVIRONMENT=development
DEBUG=False
MAX_CONCURRENT_TASKS=5

# 벡터 DB 구성
VECTOR_DB_PATH=./data/vectordb
EMBEDDING_MODEL=text-embedding-3-large
COLLECTION_PREFIX=multi_agent_

# 성능 설정
CHUNK_SIZE=512
CHUNK_OVERLAP=50
MAX_RESULTS_PER_QUERY=10
RELEVANCE_THRESHOLD=0.75
```

### 배포 요구사항

#### 로컬 개발 환경
- Python 3.10 이상
- 최소 16GB RAM
- 최소 100GB 스토리지 (벡터 DB 및 캐시용)
- CUDA 호환 GPU (선택적, 임베딩 생성 가속화용)

#### 프로덕션 환경
- Kubernetes 클러스터 또는 Docker Swarm
- 컨테이너 요구사항:
  - 베이스 이미지: Python 3.10-slim
  - CPU: 최소 4 코어, 권장 8 코어
  - 메모리: 최소 8GB, 권장 16GB
  - 스토리지: 최소 250GB SSD
- 수평적 확장성:
  - 스테이트리스 API 컨테이너
  - 분산 벡터 DB (Pinecone 또는 Qdrant)
  - 레디스 기반 작업 큐
- 모니터링:
  - Prometheus 메트릭
  - Grafana 대시보드
  - ELK 스택 로깅

#### CI/CD 파이프라인
- GitHub Actions 또는 GitLab CI 기반
- 자동화된 테스트 스위트:
  - 단위 테스트: pytest
  - 통합 테스트: 전체 파이프라인 검증
  - 성능 테스트: 지연 시간 및 처리량 벤치마크
- 배포 자동화:
  - Docker 이미지 빌드 및 푸시
  - Helm 차트를 통한 Kubernetes 배포
  - 단계적 롤아웃 전략

이 기술 구현 명세서는 LangGraph 기반 멀티 에이전트 시스템의 구체적인 기술 스택과 아키텍처를 정의합니다. OpenAI GPT-4o를 핵심 LLM으로 활용하고, Google Search API와 arXiv API를 통합하여 포괄적인 정보 검색 기능을 제공합니다. 모든 모듈과 인터페이스는 확장성과 유지보수성을 고려하여 설계되었습니다.